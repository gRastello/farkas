\documentclass[italian, letter paper, 12pt, reqno]{article}
\usepackage[italian]{babel}

\setlength{\evensidemargin}{0.1in}
\setlength{\oddsidemargin}{0.1in}
\setlength{\textwidth}{6.3in}
\setlength{\topmargin}{0.0in}
\setlength{\textheight}{8.5in}
\setlength{\headheight}{0in}

% Links and references.
\usepackage{xcolor}
\definecolor{Myblue}{rgb}{0,0,0.6}
\usepackage[a4paper,colorlinks,citecolor=Myblue,linkcolor=Myblue,urlcolor=Myblue,pdfpagemode=None]{hyperref}

% Necessities for math.
\usepackage{amsmath, amscd, amssymb, mathrsfs, accents, amsfonts, amsthm}

\newtheoremstyle{myteo}{\topsep}{\topsep}
	{}
	{}
	{\bfseries}
	{.}
	{2pt}
	{\thmname{#1}\thmnumber{ #2}\thmnote{ (#3)}}
\theoremstyle{myteo}

\newtheorem{theorem}{Teorema}[section]
\newtheorem{proposition}[theorem]{Proposizione}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollario}
\newtheorem{definition}[theorem]{Definizione}
\newtheorem{example}[theorem]{Esempio}
\newtheorem{remark}[theorem]{Osservazione}

\numberwithin{equation}{section}

\usepackage{tikz}
\usetikzlibrary{cd}

% Figures stuff.
\usepackage{caption}
\renewcommand{\thefigure}{\arabic{section}.\arabic{figure}}

% Lists stuff.
\usepackage{enumitem}
\setenumerate{label=(\arabic*)}

% Commands.

% Useless stuff.
\usepackage{epigraph}

\begin{document}
\title{Il Lemma di Farkas}
\author{Gabriele Rastello}
\maketitle
\tableofcontents

\section{Problemi lineari}
\epigraph{Linear programming, surprisingly, is not directly related to computer programming.}{\textit{Jiri Matousek, Bernd Garter}}
Sono problemi lineari tutti quei problimi in cui ci si prefigge di trovare il valore massimo (o minimo) che una certa funzione lineare di \(n\) variabili può assumere, dato un qualche numero di vincoli (anche essi lineari) su queste variabili.
Prima di definire formalmente un problema lineare consideriamo un esempio.

\begin{example}
  \label{es:problema_lineare}
  \begin{equation*}
    \begin{array}{ll}
      \text{Massimizza} & x_1 + x_2\\
      \text{rispetto ai vincoli} & x_1, x_2\geq 0\\
                        & x_2 - x_1 \leq 1\\
                        & x_1 + 6x_2 \leq 15\\
                        & 4x_1 - x_2 \leq 10
    \end{array}
  \end{equation*}
  In \(\mathbb{R}^2\) ogni vincolo individua un semipiano.
  La zona di \(\mathbb{R}^2\) su cui vogliamo massimizzare \(x_1+x_2\) è dunque l'intersezione di tutti questi semipiani ed è rappresentata in Figura \ref{fig:problema_lineare}.
  Osserviamo che quest'area non è vuota e che è un poligono convesso.
  Esiste dunque una coppia \((x_1^*,x_2^*)\) che massimizza \(x_1+x_2\); la coppia in questione può essere ottenuta cercando quale punto del poligono si trova ``più distante'' nella direzione di massima crescita della funzione (data dal suo gradiente \((1, 1)\)).
  Otteniamo così \(x_1^*=3, x_2^*=2\) e infine che il valore massimo di \(x_1+x_2\) rispetto ai vincoli dati è \(5\).

  \begin{figure}
    \begin{center}
      \begin{tikzpicture}
        \filldraw[fill=green!20!white]
        (0, 0) -- (0, 1) -- (9/7, 16/7) -- (3, 2) -- (10/4, 0);

        \draw[->] (-1, 0) -- (4, 0) node[right]{\(x_1\)};
        \draw[->] (0, -1) -- (0, 3.5) node[above]{\(x_2\)};

        \draw[domain = -.75:3.25] plot (\x, {\x + 1});
        \draw[domain = -.75:4] plot (\x, {(15 - \x)/6});
        \draw[domain = 2.25:3.5] plot (\x, {4*\x - 10});

        \filldraw (3, 2) circle (3pt) node[above right]{\((3,2)\)};
      \end{tikzpicture}
    \end{center}
    \caption{}
    \label{fig:problema_lineare}
  \end{figure}
\end{example}

\begin{definition}
  \label{def:problema_lineare}
  Un \textbf{problema lineare} consiste in una funzione lineare di \(n\) variabili detta \textbf{funzione obiettivo} (o \textbf{funzione di costo}) e in un insieme di \(m\) vincoli lineari.
  La funzione obiettivo ha la forma \(\mathbf{c}^T\mathbf{x} = c_1x_1+\ldots+c_nx_n\) per qualche \(\mathbf{c}\in\mathbb{R}^n\); lo stesso si applica ai vincoli.
  Dare un problema lineare è allora equivalente a dare un vettore \(\mathbf{c}\in\mathbb{R}^n\), una matrice \(A\in\mathbb{R}^{m\times n}\) e un vettore \(\mathbf{b}\in\mathbb{R}^m\).
  Scriveremo compattamente
  \begin{equation*}
    \begin{array}{ll}
      \text{Massimizza} & \mathbf{c}^T\mathbf{x}\\
      \text{rispetto ai vincoli} & A\mathbf{x}\leq\mathbf{b}.
    \end{array}
  \end{equation*}
\end{definition}

\begin{remark}
  \label{oss:definizione_generale}
  La Definizione \ref{def:problema_lineare} è del tutto generale.
  Infatti un problema di minimizzazione può essere trasformato in uno di massimizzazione cambiando segno alla funzione obiettivo.
  I vincoli espressi tramite un'uguaglianza \(\mathbf{a}^T\mathbf{x}=b\) sono equivalenti alla coppia di disuguaglianze \(\mathbf{a}^T\mathbf{x}\geq b\), \(\mathbf{a}^T\mathbf{x}\leq b\).
  Ed infine le disuguaglianze possono essere espresse tutte quante nella forma \(\mathbf{a}^T\mathbf{x}\leq b\).
\end{remark}

\begin{definition}
  \label{def:soluzioni}
  Un vettore \(\mathbf{x}\in\mathbb{R}^n\) che soddisfa tutti i vincoli di un problema lineare è una \textbf{soluzione possibile} per il problema.
  Un problema è \textbf{soddisfacibile} se ammette una soluzione possibile ed è \textbf{insoddisfacibile} altrimenti. Una soluzione possibile \(\mathbf{x}^*\in\mathbb{R}^n\) è una \textbf{soluzione ottimale} se \(\mathbf{c}^T\mathbf{x}^*\) è massimo tra i valori \(\mathbf{c}^T\mathbf{x}\) con \(\mathbf{x}\) soluzione possibile.
\end{definition}

\begin{remark}
  \label{oss:soluzioni_ottimali_illimitate}
  Va osservato che, generalmente, un sistema lineare può avere più di una soluzione ottimale; come esempio si considerino i vincoli dell'Esercizio \ref{es:problema_lineare} applicati però alla funzione obiettivo \(\frac{1}{6}x_1+x_2\).
  È inoltre vero che, anche se un sistema è soddisfacibile, possono non esistere soluzioni ottimali; come esempio basta rimuovere i vincoli \(x_1+6x_2\leq15\) e \(4x_1-x_2\leq10\) dall'Esercizio \ref{es:problema_lineare}.
\end{remark}

\begin{definition}
  \label{def:problemi_limitati_e_illimitati}
  Se un problema lineare ammette (almeno) una soluzione ottimale allora è detto \textbf{limitato}; se non ne ammette viene detto \textbf{illimitato}.
\end{definition}

Concludiamo la sezione con un esempio di applicazione dei problemi lineari all'analisi numerica (in particolare alla regressione lineare) e con un'osservazione sulla difficoltà computazionale della ricerca di soluzioni (possibili e ottimali) ad un dato problema lineare.

\begin{example}
  \label{es:minimi_quadrati}
  Dato un insieme di punti \(\{(x_i, y_i)\colon\ i=1,\ldots,n\}\) di \(\mathbb{R}^2\) è possibile ottenere l'equazione di una retta che si avvicina il più possibile ai punti dati usando il \textit{metodo dei minimi quadrati}.
  L'intera tecnica è basata sul cercare \(a,b\in\mathbb{R}\) tali che
  \begin{equation*}
    \sum_{i=1}^n(ax_i + b - y_i)^2
  \end{equation*}
  sia minimo. Un metodo alternativo (e per certi lati migliore) consiste nel minimizzare direttamente la somma degli errori in valore assoluto:
  \begin{equation*}
    \tag{\(*\)}
    \sum_{i=1}^n|ax_i + b - y_i|.
  \end{equation*}
  Seppure questa quantità non sia lineare il problema può essere ridotto ad un problema lineare.
  Si consideri infatti il problema
  \begin{equation*}
    \begin{array}{lll}
      \text{Minimizza} & e_1 + \ldots + e_n &\\
      \text{rispetto ai vincoli} & e_i\geq ax_i + b - y_i &\\
                       & e_i\geq -(ax_i + b - y_i) &,\ \text{con}\ i = 1,\ldots, n.\\
    \end{array}
  \end{equation*}
  Le variabili qui sono \(a, b, e_1,\ldots, e_n\).
  Ogni \(e_i\) è una variabile ausiliaria che rappresenta l'errore relativo al punto \((x_i, y_i)\); infatti i vincoli ci assicurano che
  \[e_i\geq\max\big(ax_i + b - y_i, -(ax_i + b - y_i)\big) = |ax_i + b - y_i|.\]
  Nel caso di una soluzione ottimale tutte queste disuguaglianze devono valere come uguaglianze, altrimenti sarebbe possibile ridurre ulteriormente il corrispettivo \(e_i\).
  Ne consegue che una soluzione ottimale del problema fornisce una retta che minimizza \((*)\).
\end{example}

\begin{remark}
  \label{oss:binary_search}
  Consideriamo un problema lineare generico
  \begin{equation*}
    \begin{array}{ll}
      \text{Massimizza} & \mathbf{c}^T\mathbf{x}\\
      \text{rispetto ai vincoli} & A\mathbf{x}\leq\mathbf{b}.
    \end{array}
  \end{equation*}
  e supponiamo di sapere che \(0\leq \mathbf{c}^T\mathbf{x}\leq M\) per un \(M\in\mathbb{R}\) e ogni soluzione possibile \(\mathbf{x}\).
  Supponiamo inoltre di avere una procedura che ci permetta di sapere quando un arbitrario problema lineare è soddisfacibile.
  Allora possiamo approssimare il valore massimo di \(\mathbf{c}^T\mathbf{x}\) con una tecnica di ricerca binaria:
  \begin{enumerate}
  \item aggiungiamo al problema iniziale il vincolo \(\mathbf{c}^T\mathbf{x}\geq \frac{M}{2}\) e determiniamo se questo nuovo problema è soddisfacibile,
  \item se lo è allora il massimo di \(\mathbf{c}^T\mathbf{x}\) si trova tra \(\frac{M}{2}\) e \(M\), altrimenti si trova tra \(0\) e \(\frac{M}{2}\),
  \item ripetendo i passi (1) e (2) su questo nuovo intervallo possiamo molto velocemente localizzare il massimo.
  \end{enumerate}
  Questo ci dice che, computazionalmente, il problema di ricerca di una soluzione ottimale è tanto difficile quanto quello di ricerca di una soluzione qualunque.
\end{remark}

\section{Dualità e Lemma di Farkas}

\begin{thebibliography}{1}
\bibitem{understanding_linear_programming}
  Jiri Matousek \& Bernd Gartner,
  \textit{Understanding and Using Linear Programming},
  Springer,
  2007.
\end{thebibliography}
\end{document}
